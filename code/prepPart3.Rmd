
## PART 3: Quantile Normalisation

The previous calculations provide all information needed to filter the samples and make a tab-separated file *samplesfilefinal* for further use. 
For this analysis, `r paste(strsplit(samplesfilefinal, split = "/")[[1]][-1], collapse = "/ ")` was used as list of samples for the final preprocessing steps. 
```{r, label = QN_intro}
###############################################################################

# PART 3 (QN)

# Perform Quantile Normalization based on final sample set
# Written by Benjamin Lehne (Imperial College London) and Alexander Drong (Oxford University)
# extended by Alexander Teumer (University Medicine Greifswald/ Erasmus MC Rotterdam)
# last change: 05/16/2016

samples <- colnames(TypeI.Red.M.All.d)
samples <- unique(samples[samples %in% datsamplesfinal$Sentrix_Code])

# --- minimum callrate filtering on samples is necessary -----------
# otherwise normalizeQuantiles crashes
# since filtering is on samples, filtering is overall and not Type-wise
# this filtering step is performed in part 2 because it may result in additional sample filtering

```

`r length(men)` men and `r length(women)` women samples are included in Quantile Normalisation.

```{r, label = QN_calculation}

# ---- QN AUTOSOMES ---------------------------------

#QN autosomes # has to be filtered by samples 
category=auto

markers=as.matrix(intersect(rownames(TypeII.Green.All.d), category))
TypeII.Green = TypeII.Green.All.d[markers,samples]
TypeII.Red = TypeII.Red.All.d[markers,samples]
markers=intersect(rownames(TypeI.Green.M.All.d), category)
TypeI.Green.M = TypeI.Green.M.All.d[markers,samples]
TypeI.Green.U = TypeI.Green.U.All.d[markers,samples]
markers=intersect(rownames(TypeI.Red.M.All.d), category)
TypeI.Red.M = TypeI.Red.M.All.d[markers,samples]
TypeI.Red.U = TypeI.Red.U.All.d[markers,samples]

TypeII.Green=normalizeQuantiles(TypeII.Green)
TypeII.Red = normalizeQuantiles(TypeII.Red)
TypeI.Green.M = normalizeQuantiles(TypeI.Green.M)
TypeI.Green.U = normalizeQuantiles(TypeI.Green.U)
TypeI.Red.M = normalizeQuantiles(TypeI.Red.M)
TypeI.Red.U = normalizeQuantiles(TypeI.Red.U)
TypeII.betas = TypeII.Green/(TypeII.Red+TypeII.Green+100)
TypeI.Green.betas = TypeI.Green.M/(TypeI.Green.M+TypeI.Green.U+100)
TypeI.Red.betas = TypeI.Red.M/(TypeI.Red.M+TypeI.Red.U+100)
betaQN = as.matrix(rbind(TypeII.betas,TypeI.Green.betas,TypeI.Red.betas))
marker.callQN =rowSums(!is.na(betaQN))/ncol(betaQN) # this line is added; if problems occur, maybe delete it and rechange all lines where marker.callQN occurs to marker.call


# ---- QN SEXCHROMOSOMES ---------------------------------

category=c(sexchrX,sexchrY)


#QN men
markers=as.matrix(intersect(rownames(TypeII.Green.All.d), category))
TypeII.Green_m= TypeII.Green.All.d[markers,men]
TypeII.Red_m = TypeII.Red.All.d[markers,men]
markers=intersect(rownames(TypeI.Green.M.All.d), category)
TypeI.Green.M_m = TypeI.Green.M.All.d[markers,men]
TypeI.Green.U_m = TypeI.Green.U.All.d[markers,men]
markers=intersect(rownames(TypeI.Red.M.All.d), category)
TypeI.Red.M_m = TypeI.Red.M.All.d[markers,men]
TypeI.Red.U_m = TypeI.Red.U.All.d[markers,men]

# only if there are at least 2 men
if(length(men) > 1){
TypeII.Green_m=normalizeQuantiles(TypeII.Green_m)
TypeII.Red_m = normalizeQuantiles(TypeII.Red_m)
TypeI.Green.M_m = normalizeQuantiles(TypeI.Green.M_m)
TypeI.Green.U_m = normalizeQuantiles(TypeI.Green.U_m)
TypeI.Red.M_m = normalizeQuantiles(TypeI.Red.M_m)
TypeI.Red.U_m = normalizeQuantiles(TypeI.Red.U_m)
} else {
	cat("Quantile normalization for men was skipped, because it has no effect when there are\nless than 2 samples.")
}

TypeII.betas_m = TypeII.Green_m/(TypeII.Red_m+TypeII.Green_m+100)
TypeI.Green.betas_m = TypeI.Green.M_m/(TypeI.Green.M_m+TypeI.Green.U_m+100)
TypeI.Red.betas_m = TypeI.Red.M_m/(TypeI.Red.M_m+TypeI.Red.U_m+100)

if(length(men) > 1){
  beta_m = as.matrix(rbind(TypeII.betas_m,TypeI.Green.betas_m,TypeI.Red.betas_m))
} else {
  beta_m = c(TypeII.betas_m,TypeI.Green.betas_m,TypeI.Red.betas_m)
}

#QN women
markers=as.matrix(intersect(rownames(TypeII.Green.All.d), category))
TypeII.Green_w= TypeII.Green.All.d[markers,women]
TypeII.Red_w = TypeII.Red.All.d[markers,women]
markers=intersect(rownames(TypeI.Green.M.All.d), category)
TypeI.Green.M_w = TypeI.Green.M.All.d[markers,women]
TypeI.Green.U_w = TypeI.Green.U.All.d[markers,women]
markers=intersect(rownames(TypeI.Red.M.All.d), category)
TypeI.Red.M_w = TypeI.Red.M.All.d[markers,women]
TypeI.Red.U_w = TypeI.Red.U.All.d[markers,women]


# only if there are at least 2 women
# watch out if you change this; this switch appears several times in the code due to formatting reasons
if(length(women) > 1){
TypeII.Green_w=normalizeQuantiles(TypeII.Green_w)
TypeII.Red_w = normalizeQuantiles(TypeII.Red_w)
TypeI.Green.M_w = normalizeQuantiles(TypeI.Green.M_w)
TypeI.Green.U_w = normalizeQuantiles(TypeI.Green.U_w)
 TypeI.Red.M_w = normalizeQuantiles(TypeI.Red.M_w)
 TypeI.Red.U_w = normalizeQuantiles(TypeI.Red.U_w)
} else {
	cat("Quantile normalization for women was skipped, because it has no effect when there are less than 2 samples.")
}

TypeII.betas_w = TypeII.Green_w/(TypeII.Red_w+TypeII.Green_w+100)
TypeI.Green.betas_w = TypeI.Green.M_w/(TypeI.Green.M_w+TypeI.Green.U_w+100)
TypeI.Red.betas_w = TypeI.Red.M_w/(TypeI.Red.M_w+TypeI.Red.U_w+100)

if(length(women) > 1){
  beta_w = as.matrix(rbind(TypeII.betas_w,TypeI.Green.betas_w,TypeI.Red.betas_w))
} else {
  beta_w = c(TypeII.betas_w,TypeI.Green.betas_w,TypeI.Red.betas_w)
}

betaQN.sex <- cbind(beta_m,beta_w) 
marker.call_sex=rowSums(!is.na(betaQN.sex))/ncol(betaQN.sex)
betaQN.all <- rbind(betaQN,betaQN.sex[,match(colnames(betaQN),colnames(betaQN.sex))])

###### save data (combine with sex chr)

rm(TypeII.Green,TypeII.Red,TypeI.Green.M,TypeI.Green.U,TypeI.Red.M,TypeI.Red.U,TypeII.betas,TypeI.Green.betas,TypeI.Red.betas)
rm(TypeII.Green_m,TypeII.Red_m,TypeI.Green.M_m,TypeI.Green.U_m,TypeI.Red.M_m,TypeI.Red.U_m,TypeII.betas_m,TypeI.Green.betas_m,TypeI.Red.betas_m)
rm(TypeII.Green_w,TypeII.Red_w,TypeI.Green.M_w,TypeI.Green.U_w,TypeI.Red.M_w,TypeI.Red.U_w,TypeII.betas_w,TypeI.Green.betas_w,TypeI.Red.betas_w)

plot.beta.densities(betaQN,"Densities of normalized autosomal beta values per sample")
```

### PART 4: Principal Component Checks

Control probes track technical bias between batches. To adjust for these in the analysis while minimizing the number of variables due to convergence reasons, we calculate Principal Components and show how much variance they explain. 
Markers which had at least one cpg site missing were excluded for the following PCA. 

```{r, echo = FALSE, label = pca_controlprobes_technicalbias}
#PCA of control-probe intensities
datpca <- ctrl.all[unique(samples),]
pcaControls <- prcomp(na.omit(datpca))
ctrlprobes.scores = pcaControls$x
EV <- merge(ctrlprobes.scores,datsamples,by.x=0,by.y="Sentrix_Code")
colnames(ctrlprobes.scores) = paste(colnames(ctrlprobes.scores), '_cp', sep='')

plot(EV[,"PC1"],EV[,"PC2"], main=paste0("PCA - number of controls probes: ",ncol(datpca)),xlab=paste0("PC1 (",sprintf("%1.1f",(pcaControls$sdev^2/sum(pcaControls$sdev^2))[1]*100),"%)"),ylab=paste0("PC2 (",sprintf("%1.1f",(pcaControls$sdev^2/sum(pcaControls$sdev^2))[2]*100),"%)"))

par(mfrow=c(1,1))
plot((pcaControls$sdev^2/sum(pcaControls$sdev^2))[1:10],main="Explained Variance by control probe PCs",ylab="% variance",xlab="PC#",ylim=c(0,1.05))
text((y=pcaControls$sdev^2/sum(pcaControls$sdev^2))[1:10],x=1:10+0.1,labels=sprintf("%1.3f",(pcaControls$sdev^2/sum(pcaControls$sdev^2)))[1:10],adj=c(0.5,-1))

ctrlprobes.scores <- merge(ctrlprobes.scores,datsamples[,c("Sentrix_Code","Sample_Name")],by.x=0,by.y="Sentrix_Code")
write.csv(ctrlprobes.scores,file=paste0(outputdir,"/PC_controls-finalSample","_",projectname,"-",formatted.time,".csv"),row.names=F)
```
  
The following plots show the call rates of the sex chromosomes stratified per sex. 

```{r, echo = FALSE, label = sexchr_callrates}


# sex-check
sample.callY=colSums(!is.na(betaQN.sex[sexchrY,]))/nrow(betaQN.sex[sexchrY,])
sample.callX=colSums(!is.na(betaQN.sex[sexchrX,]))/nrow(betaQN.sex[sexchrX,])

# plot sex call rates
YcallMen <- sample.callY[names(sample.callY) %in% men]
YcallWomen <- sample.callY[names(sample.callY) %in% women]
#par(mfrow=c(2,1))

if(length(men) > 1){
hist(YcallMen,breaks=50)
}
```
  



```{r, echo = FALSE, label = histogram_womensexcall}
if(length(women) > 1){
hist(YcallWomen,breaks=50)

marker.callYwomen=rowSums(!is.na(betaQN.sex[sexchrY,colnames(betaQN.sex) %in% women]))/ncol(betaQN.sex[sexchrY,colnames(betaQN.sex) %in% women])
}
```
  



```{r, label = histogram_womensexcall2}
if(length(women) > 1){
par(mfrow=c(1,1))
hist(marker.callYwomen,breaks=50)
}
```

Now a PCA will be conducted on autosomal beta values after quantile normalisation. Here we investigate how well the markers can be separated by choosing different base vectors. 
Rows are observations, here markers.

```{r, label = pca_autosome_postQN}
# PCA variables (autosomes)
betaPCA <- betaQN
pcaAuto <- prcomp(na.omit(betaPCA))
# EV <- pcaAuto$rotation
# EV <- merge(EV,datsamples,by.x=0,by.y="Sentrix_Code")
# par(mfrow=c(1,1))
# plot(EV[,"PC1"],EV[,"PC2"], main=paste0("number of autosomal probes: ",nrow(pcaAuto$x)),xlab=paste0("EV1 (",sprintf("%1.1f",(pcaAuto$sdev^2/sum(pcaAuto$sdev^2))[1]*100),"%)"),ylab=paste0("EV2 (",sprintf("%1.1f",(pcaAuto$sdev^2/sum(pcaAuto$sdev^2))[2]*100),"%)"))
# 
# plot(EV[,"PC3"],EV[,"PC4"], main=paste0("number of autosomal probes: ",nrow(pcaAuto$x)),xlab=paste0("EV3 (",sprintf("%1.1f",(pcaAuto$sdev^2/sum(pcaAuto$sdev^2))[3]*100),"%)"),ylab=paste0("EV4 (",sprintf("%1.1f",(pcaAuto$sdev^2/sum(pcaAuto$sdev^2))[4]*100),"%)"))

```


```{r, label = plot_pca_autosome_postQN}
# EVals
par(mfrow=c(1,1))
plot((pcaAuto$sdev^2/sum(pcaAuto$sdev^2))[1:10],main="Explained Variance of markers on autosomes",ylab="% variance",xlab="PC#",ylim=c(0,1.05))
text((y=pcaAuto$sdev^2/sum(pcaAuto$sdev^2))[1:10],x=1:10+0.1,labels=sprintf("%1.3f",(pcaAuto$sdev^2/sum(pcaAuto$sdev^2)))[1:10],adj=c(0.5,-1))

marker.call.all <- data.frame(callrate=c(marker.callQN,marker.call_sex)) # marker callrate of all samples incl. excluded ones
```

The next PCA is also calculated on the quantile normalized beta values (omitting missing values), but now such that the first principal component explains most of the variation of the autosomal sample data. 
This is the same data as used in the plot before, but with transposed data (rows are observations, thus samples).
So the variation which is explained by the first pricipal component indicates how well the samples can be separated by choosing a new base vector.


```{r, warnings = FALSE, plot_transposed_pca_autosome_postQN} 
pca.col.plot2 <- function(pc, group,legend,col_pal, header = ""){
p1 <- fviz_pca_ind(pc,axes=c(1,2),
		     col.ind = group, # color by groups # if there are more than 25 groups, this will cause a warning or an error !!
             palette = col_pal, geom="point",
             addEllipses = TRUE, # Concentration ellipses
             ellipse.type = "confidence", legend.title = header, repel = FALSE)

p2 <- fviz_pca_ind(pc,axes=c(3,4),
		     col.ind = group, # color by groups
             palette = col_pal, geom="point",
             addEllipses = TRUE, # Concentration ellipses
             ellipse.type = "confidence", legend.title = header, repel = FALSE)

# p3 <- fviz_pca_ind(pc,axes=c(5,6),
# 		     col.ind = group, # color by groups
#              palette = col_pal, geom="point",
#              addEllipses = TRUE, # Concentration ellipses
#              ellipse.type = "confidence", legend.title = header, repel = FALSE)
return(list(p1,p2)) #,p3))
}



# PCA samples (autosomes)
betaPCA <- betaQN
pcaSamples <- prcomp(t(na.omit(betaPCA)))
EV <- pcaSamples$x
EV <- merge(EV,datsamples,by.x=0,by.y="Sentrix_Code")
plot(cumsum((pcaSamples$sdev^2/sum(pcaSamples$sdev^2)))[1:10],main="Cumulative explained variance between samples",ylab="% variance",xlab="number of PCs",ylim=c(0,1.05))
```

```{r, label = plot_samplevariance_postQN} 
plot((pcaSamples$sdev^2/sum(pcaSamples$sdev^2))[1:10],main="Explained variance between samples",ylab="% variance",xlab="number of PCs",ylim=c(0,1.05))
text((y=pcaSamples$sdev^2/sum(pcaSamples$sdev^2))[1:10],x=1:10+0.1,labels=sprintf("%1.3f",(pcaSamples$sdev^2/sum(pcaSamples$sdev^2)))[1:10],adj=c(0.5,-1))

```
 
The following plots show these principal components colored by Sentrix_ID and Sample_Plate.
Because color coding for more than 18 groups is problematic, we split the batch variable in disjoint random groups of maximum 17 members and plot each group together with a 18th member who summarizes the other batches. For each group of 18 batches, we plot the PCs 1&2 and 3&4. 

First, we plot regarding *Sentrix_ID*:

```{r, warnings = FALSE, label = plots_batcheffects_postQN_sentrix} 

# pdf(file=paste0(outputdir,"/results-PCAauto-QN-platewise","_",projectname,"-",formatted.time,".pdf"),height=21,width = 21)
# par(mar=c(8.1,7.1,4.1,2.1))

make.fancy.PCA.plots = function(batchvariable){
	matched_category = datsamples[match(rownames(pcaSamples$x),datsamples$Sentrix_Code),batchvariable] 
	
	if(length(unique(matched_category)) > 150){ 
	cat("\nWe will investigate batch effects with respect to ", batchvariable, " \n using quartiles as there are  more than 150 of these batches.\n")
		matched_category = as.numeric(matched_category)
		q = summary(matched_category)[c("Min.","1st Qu.","Median","3rd Qu.","Max.")]
		matched_category = cut(matched_category, breaks = q)
	} 
	
	if(!batchvariable%in%colnames(datsamples)){
		cat("\n",batchvariable,"\n is not provided by phenotype data.\n")
	} else if(length(unique(matched_category)) < 2){ 
		cat("\nThere is no point in investigating batch effects with respect to ", batchvariable, " \n as there are less than two of these batches.\n")
	} else {
	

	# We can only plot up to 19 plates at the same time, so we plot 18 single plates and one (all-others-plate)
	max.categories.per.block<-18
	unique_categories = unique(matched_category)
	number.of.blocks = ceiling(length(unique_categories)/max.categories.per.block) 
	for( i in 1:number.of.blocks){
		plot_categories = matched_category
		if(i<number.of.blocks){
			selected_categories <-
unique_categories[c(((i-1)*max.categories.per.block+1):(i*max.categories.per.block))]
		}else{
			selected_categories <- unique_categories[c(((i-1)*max.categories.per.block+1):length(unique_categories))]
		}
plot_categories[-which(plot_categories %in% selected_categories)] <- paste("all other",batchvariable)

	tmp <- pca.col.plot2(pc = pcaSamples,
						 group=factor(plot_categories), 
						 legend=levels(factor(plot_categories)),
						 col_pal=rainbow(n=length(unique(plot_categories)))
						)
	print(tmp[[1]])
	print(tmp[[2]])
#	tmp[[3]]
	}
	# dev.off()
}
}

make.fancy.PCA.plots("Sentrix_ID")
```

Additionally we supply the Sentrix_IDs of outliers (defined by three times the standard deviation per PC). They are exported to the file 
`r cat(paste0("samples-with-batch-effect_",projectname,"-",formatted.time,".csv"),"\n")`.


```{r, label = plots_batcheffects_postQN_sentrix2}
EV = as.data.frame(pcaSamples$x)
plot(EV$PC1, EV$PC2, main = "Label outliers (3*SD)", xlab = "PC1", ylab = "PC2")
batch.effect.samples12 = mark.outliers(EV$PC1, EV$PC2,"blue",rownames(EV), sd.range = 3, color.points = TRUE)
print(batch.effect.samples12)

plot(EV$PC3, EV$PC4, main = "Label outliers (3*SD)", xlab = "PC3", ylab = "PC4")
batch.effect.samples34 = mark.outliers(EV$PC3, EV$PC4,"blue",rownames(EV), sd.range = 3, color.points = TRUE)
print(batch.effect.samples34)

batch.effect.samples = unique(c(batch.effect.samples12, batch.effect.samples34))
batch.effect.info = datsamples[datsamples$Sentrix_Code%in%batch.effect.samples,]
all.batch.effect.info = cbind(batch.effect.info, EV[batch.effect.info$Sentrix_Code,c("PC1","PC2","PC3","PC4")])

write.csv(batch.effect.samples,file = paste0(outputdir,"/samples-with-batch-effect","_",projectname,"-",formatted.time,".csv"),row.names=F)
```

Next, we plot with respect to *Sample_Plate*:

```{r, label = plots_batcheffects_postQN_plate}
make.fancy.PCA.plots("Sample_Plate")

```

To better understand these results, compare the **number of samples per Plate**.
```{r, label = plots_batcheffects_postQN_plate2}
number.of.samples.per.plate = sapply(unique(datsamples$Sample_Plate), function(n){sum(datsamples$Sample_Plate%in%n)})
print(number.of.samples.per.plate)
```

```{r, label = plots_batcheffects_postQN_additional}
if(exists("additionalBatchVariables")){
	if(additionalBatchVariables){
		BatchVariables = read.table(BatchVariablesFile, header = FALSE, stringsAsFactors = F)$V1
		for( batchvariable in BatchVariables){
			if(batchvariable%in%colnames(datsamples)){
				make.fancy.PCA.plots(batchvariable)		
			} else {
				cat("\n",batchvariable, "is not reported by the samplesfile.\n")
		  }
	  }
	}
}
```

